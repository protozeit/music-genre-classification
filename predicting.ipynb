{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.optimizers import RMSprop, Nadam\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               26624     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 61,704\n",
      "Trainable params: 61,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=207, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/DNN.h5')\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns():\n",
    "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
    "                         spectral_centroid=1, spectral_bandwidth=1,\n",
    "                         spectral_contrast=7, spectral_rolloff=1)\n",
    "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
    "\n",
    "    columns = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
    "            columns.extend(it)\n",
    "\n",
    "    names = ('feature', 'statistics', 'number')\n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
    "\n",
    "    # More efficient to slice if indexes are sorted.\n",
    "    return columns.sort_values()\n",
    "\n",
    "\n",
    "def compute_features2(songname):\n",
    "\n",
    "            features = []           \n",
    "            \n",
    "            y, sr = librosa.load(songname, duration=30)\n",
    "            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            rmse = librosa.feature.rms(y=y)\n",
    "            cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "            features.append(tempo)\n",
    "            features.append(np.sum(beats))\n",
    "            features.append(np.mean(chroma_stft))\n",
    "            features.append(np.mean(rmse))\n",
    "            features.append(np.mean(cent))\n",
    "            features.append(np.mean(spec_bw))\n",
    "            features.append(np.mean(rolloff))\n",
    "            features.append(np.mean(zcr))\n",
    "            for coefficient in mfcc:\n",
    "                features.append(np.mean(coefficient))\n",
    "            \n",
    "\n",
    "            return features\n",
    "        \n",
    "        \n",
    "def compute_features(filepath):\n",
    "\n",
    "    features = pd.Series(index=columns(), dtype=np.float32, name=filepath)\n",
    "\n",
    "    # Catch warnings as exceptions (audioread leaks file descriptors).\n",
    "    warnings.filterwarnings('error', module='librosa')\n",
    "\n",
    "    def feature_stats(name, values):\n",
    "        features[name, 'mean'] = np.mean(values, axis=1)\n",
    "        features[name, 'std'] = np.std(values, axis=1)\n",
    "        features[name, 'skew'] = stats.skew(values, axis=1)\n",
    "        features[name, 'kurtosis'] = stats.kurtosis(values, axis=1)\n",
    "        features[name, 'median'] = np.median(values, axis=1)\n",
    "        features[name, 'min'] = np.min(values, axis=1)\n",
    "        features[name, 'max'] = np.max(values, axis=1)\n",
    "\n",
    "    try:\n",
    "        x, sr = librosa.load(filepath, sr=None, mono=True)  # kaiser_fast\n",
    "\n",
    "        f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "        feature_stats('zcr', f)\n",
    "\n",
    "        cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                 n_bins=7*12, tuning=None))\n",
    "        assert cqt.shape[0] == 7 * 12\n",
    "        assert np.ceil(len(x)/512) <= cqt.shape[1] <= np.ceil(len(x)/512)+1\n",
    "\n",
    "        f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "        feature_stats('chroma_cqt', f)\n",
    "        f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "        feature_stats('chroma_cens', f)\n",
    "        f = librosa.feature.tonnetz(chroma=f)\n",
    "        feature_stats('tonnetz', f)\n",
    "\n",
    "        del cqt\n",
    "        stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "        assert stft.shape[0] == 1 + 2048 // 2\n",
    "        assert np.ceil(len(x)/512) <= stft.shape[1] <= np.ceil(len(x)/512)+1\n",
    "        del x\n",
    "\n",
    "        f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "        feature_stats('chroma_stft', f)\n",
    "\n",
    "        f = librosa.feature.rms(S=stft)\n",
    "        feature_stats('rmse', f)\n",
    "\n",
    "        f = librosa.feature.spectral_centroid(S=stft)\n",
    "        feature_stats('spectral_centroid', f)\n",
    "        f = librosa.feature.spectral_bandwidth(S=stft)\n",
    "        feature_stats('spectral_bandwidth', f)\n",
    "        f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "        feature_stats('spectral_contrast', f)\n",
    "        f = librosa.feature.spectral_rolloff(S=stft)\n",
    "        feature_stats('spectral_rolloff', f)\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "        del stft\n",
    "        f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "        feature_stats('mfcc', f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('{}: {}'.format(filepath, repr(e)))\n",
    "\n",
    "    return features\n",
    "\n",
    "genre_dict = {\n",
    "    'Hip-Hop': 0,\n",
    "    'Pop': 1,\n",
    "    'Folk': 2,\n",
    "    'Rock': 3,\n",
    "    'Experimental': 4,\n",
    "    'International': 5,\n",
    "    'Electronic': 6,\n",
    "    'Instrumental': 7,\n",
    "}\n",
    "\n",
    "inv_genre_dict = {v: k for k, v in genre_dict.items()}\n",
    "\n",
    "genre_names = [inv_genre_dict[i] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = compute_features('songs/club.wav')\n",
    "test2 = compute_features('songs/rock.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature      statistics  number\n",
      "chroma_cens  kurtosis    01        0.065404\n",
      "                         02        0.431405\n",
      "                         03       -0.404023\n",
      "                         04        0.254728\n",
      "                         05        0.207687\n",
      "Name: songs/rock.wav, dtype: float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(518,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test2.head())\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08777935, 0.10765458, 0.06566357, 0.13068023, 0.04024485,\n",
       "        0.15346232, 0.34702435, 0.06749073],\n",
       "       [0.02657715, 0.21792585, 0.06786897, 0.01259747, 0.20324834,\n",
       "        0.02076952, 0.16486531, 0.28614733]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "X = test.to_frame().T\n",
    "X2 = test2.to_frame().T\n",
    "X = pd.concat([X,X2])\n",
    "\n",
    "pca = pickle.load(open('pca','rb'))\n",
    "\n",
    "X = skl.preprocessing.StandardScaler().fit_transform(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "print(inv_genre_dict[model.predict_classes(X)[0]])\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09499289, 0.06599655, 0.14774106, 0.07535625, 0.1112358 ,\n",
       "        0.11708879, 0.24027342, 0.14731522]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pca.transform(skl.preprocessing.StandardScaler().fit_transform(test2.to_frame().T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = utils.load('fma_metadata/tracks.csv')\n",
    "genres = utils.load('fma_metadata/genres.csv')\n",
    "\n",
    "genre1 = tracks['track', 'genre_top'] == 'Rock'\n",
    "genre2 = tracks['track', 'genre_top'] == 'Electronic'\n",
    "\n",
    "small = tracks['set', 'subset'] <= 'small'\n",
    "\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "features = utils.load('fma_metadata/features.csv')\n",
    "X_train = features.loc[small & train]\n",
    "\n",
    "y_train = tracks.loc[small & train, ('track', 'genre_top')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 207)\n",
      "[[ 0.49028565 -0.23754468  1.15523324 ...  0.33788714 -0.1318657\n",
      "  -0.32881255]\n",
      " [ 0.33306596 -0.4497311   0.65844177 ... -0.1667848  -2.14088161\n",
      "  -0.22367863]\n",
      " [ 0.98226792  0.57648104  0.87899976 ...  0.38557993  0.37012294\n",
      "  -1.24481511]\n",
      " ...\n",
      " [-1.0239342  -1.34514829 -1.72477356 ...  1.72420224  0.40600813\n",
      "  -1.67254315]\n",
      " [-1.1460063  -0.55585006 -0.06354943 ...  0.76673139 -0.64436658\n",
      "  -0.31156717]\n",
      " [-0.89734092 -0.92808442 -0.97449704 ... -0.93360767 -1.04206242\n",
      "   1.21609842]]\n",
      "(6400, 207)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6400,207) (518,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-fdb0d0edcd0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6400,207) (518,) "
     ]
    }
   ],
   "source": [
    "'''print(X_train.shape)\n",
    "X_train = X_train.iloc[0]\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "X_train = skl.preprocessing.StandardScaler().fit_transform(X_train.to_frame())\n",
    "\n",
    "X_train = pca.transform(X_train.T)\n",
    "predictions = model.predict_classes(X_train)'''\n",
    "print(X_train.shape)\n",
    "X_train = skl.preprocessing.StandardScaler().fit_transform(X_train)\n",
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "X_train = pca.transform(X_train)\n",
    "print(X_train.shape)\n",
    "predictions = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-db0ccfdf8e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdraw_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DNN_cm.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-db0ccfdf8e1c>\u001b[0m in \u001b[0;36mdraw_cm\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def draw_cm(model, filename):\n",
    "    y_predict = model.predict_classes(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in genre_names],\n",
    "                      columns = [i for i in genre_names])\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(df_cm, cmap='hot')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(np.arange(8))\n",
    "    ax.set_yticks(np.arange(8))\n",
    "    ax.set_xticklabels(genre_names)\n",
    "    ax.set_yticklabels(genre_names)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "draw_cm(model, 'DNN_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
